0.0826  , 1.2792 ,  1.0469  , 0.8124 ,  0.4436 ,  1.7177  ,
1.9851)
s=c(0.4614  ,  0.4265    ,0.2573 ,   0.2591   , 0.1670  ,  0.1680 ,
0.3412,    0.3138  ,  0.9245  ,  0.7416 ,   0.5215   , 1.4508 ,   0.3798   ,
0.2871,    0.5730,    0.4878 ,   0.2708  ,  0.2313   , 0.6929   , 0.3928,
0.4588  ,  0.4427  ,  0.4935  ,  0.4391  ,  0.5048 ,   0.1841   , 0.6403
,0.4526   , 0.5878 ,   0.4131,    0.4065,    0.5825  ,  0.4871 ,   0.2724
,0.3229   , 0.6648   , 0.8016, 0.223,0.072,0.0349,0.1309,0.8382,2.1873)
b=c(1,     1  ,   1   ,  1   ,  1  ,   1    , 1    , 1   ,
1  ,   1    , 1 ,    1  ,   2 ,    2  ,   2  ,   2 ,    1,     1   ,  1  ,   1
,  1  ,   1     ,1    , 1   ,  1,     1   ,  1    , 1  ,   1   ,  1   ,  1
,1    , 1   ,  1   ,  1  ,   1    , 1)
t=c(2 ,    3  ,   2  ,   3   ,  2    ,
3,    2    , 3   ,  2     ,3  ,   2  ,   3  ,   3 ,    3    , 3 ,    3    , 3
,  3  ,   3   ,  3   ,  3,     3,     3   ,  3   ,  3 ,    3 ,    3  ,   3  ,
3  ,   3 ,    2   ,  2   ,  2  ,   2,    2,     2 ,
2)
des=c(1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4)
rho1=c(1.1,1.1,1.1,1.1,1.1)
mydata<-list(y=y,s=s,l1=l1,l2=l2,u1=u1,u2=u2,N=N, NT=NT, D=D,c=c,b=b,t=t,des=des,rho1=rho1)
# data
l1=c(0.9999,0.9999,0.9999,0.9999)
l2=c(0.9999,0.9999,0.9999,0.9999)
u1=c(0.9999,0.9999,0.9999,0.9999)
u2=c(0.9999,0.9999,0.9999,0.9999)
N=37
D=4
NT=3
c=c(0.0859,0.0859,0.0307,0.0307,0.0106,0.0106,0.0420,0.0420,0.2833,0.2833,0.0947,0.0947)
y=c(
0.7022 ,  0.2122 ,  0.3465  , 0.4755 ,  0.4074  , 0.4208  , 1.2109,   0.7610,
2.8214  , 1.3863  , 0.7591 ,  3.3009 ,  0.0465 ,  0.0273 ,   -0.6032,   0.7899
,  0.1464  , 1.0692 ,  0.4055 ,  0.2080 ,  1.3800 ,  1.3128  ,  -0.8850
,0.4507 ,  0.8012 ,  0.1222,   1.8558 ,   -0.3054 ,  1.2217  , 0.6301,
0.0826  , 1.2792 ,  1.0469  , 0.8124 ,  0.4436 ,  1.7177  ,
1.9851)
s=c(0.4614  ,  0.4265    ,0.2573 ,   0.2591   , 0.1670  ,  0.1680 ,
0.3412,    0.3138  ,  0.9245  ,  0.7416 ,   0.5215   , 1.4508 ,   0.3798   ,
0.2871,    0.5730,    0.4878 ,   0.2708  ,  0.2313   , 0.6929   , 0.3928,
0.4588  ,  0.4427  ,  0.4935  ,  0.4391  ,  0.5048 ,   0.1841   , 0.6403
,0.4526   , 0.5878 ,   0.4131,    0.4065,    0.5825  ,  0.4871 ,   0.2724
,0.3229   , 0.6648   , 0.8016, 0.223,0.072,0.0349,0.1309,0.8382,2.1873)
b=c(1,     1  ,   1   ,  1   ,  1  ,   1    , 1    , 1   ,
1  ,   1    , 1 ,    1  ,   2 ,    2  ,   2  ,   2 ,    1,     1   ,  1  ,   1
,  1  ,   1     ,1    , 1   ,  1,     1   ,  1    , 1  ,   1   ,  1   ,  1
,1    , 1   ,  1   ,  1  ,   1    , 1)
t=c(2 ,    3  ,   2  ,   3   ,  2    ,
3,    2    , 3   ,  2     ,3  ,   2  ,   3  ,   3 ,    3    , 3 ,    3    , 3
,  3  ,   3   ,  3   ,  3,     3,     3   ,  3   ,  3 ,    3 ,    3  ,   3  ,
3  ,   3 ,    2   ,  2   ,  2  ,   2,    2,     2 ,
2)
des=c(1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4)
rho1=c(1.1,1.1,1.1,1.1,1.1)
mydata<-list(y=y,s=s,l1=l1,l2=l2,u1=u1,u2=u2,N=N, NT=NT, D=D,c=c,b=b,t=t,des=des,rho1=rho1)
Copas.fullmodel <- function(l1,l2,u1,u2,D,s,N,NT,c,y,des,t,b,rho1){
# D is the number of different designs
# lower and upper are the lowest and highest selection probabilities for each design. In the case of no publication bias they are set equal to 0.9999. There are four designs, design ABC pertains to studies 1-6, design BC to studies 7-10, design AC to studies 11-24 and design AB to studies 25-31.
#Studies that refer to design ABC report two effect sizes and two standard errors and one covariance. For ABC studies, effect sizes are y(1:12), standard errors are s(1:12) and covariances are denoted by vector c
# in this code, design 1 refers to ABC studies, design 2 to BC studies, design 3 to AC studies and design 4 to AB studies
for(j in 1:D){
lower[j]~dunif(l1[j],l2[j])
upper[j]~dunif(u1[j],u2[j])
}
# find the minimum and maximum standard error for designs 2-4
smin[2]<-min(s[13:16],)
smax[2]<-max(s[13:16],)
smin[3]<-min(s[17:30],)
smax[3]<-max(s[17:30],)
smin[4]<-min(s[31:37],)
smax[4]<-max(s[31:37],)
for (j in 2:D){
gu[j]<-upper[j]-0.5
gl[j]<-lower[j]-0.5
# estimate the  normal inverted cumulative distribution function
invNCDFU[j]<-5.531*(pow(upper[j]/(1-upper[j]),0.1193)-1)*step(-gu[j])-5.531*(pow((1-upper[j])/upper[j],0.1193)-1)*step(gu[j])
invNCDFL[j]<-5.531*(pow(lower[j]/(1-lower[j]),0.1193)-1)*step(-gl[j])-5.531*(pow((1-lower[j])/lower[j],0.1193)-1)*step(gl[j])
# estimate alpha and beta for each design
beta[j]<-(invNCDFL[j]-invNCDFU[j])/(1/smax[j]-1/smin[j])
alpha[j]<-invNCDFU[j]-beta[j]/smin[j]
}
# estimate the generalized variance for all multi-arm trials
for (i in 1:6) {
S[i]<-sqrt(abs(pow(s[2*i-1],2)*pow(s[2*i],2)-pow(c[2*i],2)))
}
# find the minimum and maximum generalized variance for design 1
smin[1]<-min(S[],)
smax[1]<-max(S[],)
gu[1]<-upper[1]-0.5
gl[1]<-lower[1]-0.5
# estimate the  normal inverted cumulative distribution function
invNCDFU[1]<-5.531*(pow(upper[1]/(1-upper[1]),0.1193)-1)*step(-gu[1])-5.531*(pow((1-upper[1])/upper[1],0.1193)-1)*step(gu[1])
invNCDFL[1]<-5.531*(pow(lower[1]/(1-lower[1]),0.1193)-1)*step(-gl[1])-5.531*(pow((1-lower[1])/lower[1],0.1193)-1)*step(gl[1])
beta[1]<-(invNCDFL[1]-invNCDFU[1])/(1/smax[1]-1/smin[1])
alpha[1]<-invNCDFU[1]-beta[1]/smin[1]
# write down the conditional distribution functions for y_AB|z and y_AC|y_AB,z
for(i in 1:6)  {
u[2*i-1]<-alpha[des[2*i-1]]+beta[des[2*i-1]]/sqrt(S[i])
u[2*i]<-u[2*i-1]
z[2*i-1]~dnorm(u[2*i-1],1) %_% T(0,)
z[2*i]<-z[2*i-1]
y[2*i-1]~dnorm(my[2*i-1],w[2*i-1])
y[2*i]~dnorm(my[2*i],w[2*i])
my[2*i-1]<-mu[2*i-1]+R[2*i-1]
my[2*i]<-mu[2*i]+R[2*i]
R[2*i-1]<-rho[des[2*i-1]]*s[2*i-1]*(z[2*i-1]-u[2*i-1])
R[2*i]<-((rho[des[2*i]+1]*s[2*i]*pow(s[2*i-1],2)-c[2*i]*rho[des[2*i-1]]*s[2*i-1])*
(z[2*i]-u[2*i])+(c[2*i]-rho[des[2*i-1]]*rho[des[2*i]+1]*s[2*i-1]*s[2*i])*(y[2*i-1]-mu[2*i-1]))/(pow(s[2*i-1],2)*(1-pow(rho[des[2*i-1]],2)))
vy[2*i-1]<-pow(s[2*i-1],2)*(1-pow(rho[des[2*i-1]],2))
vy[2*i]<-pow(s[2*i],2)-(pow(rho[des[2*i]+1],2)*pow(s[2*i-1],2)*pow(s[2*i],2)-2*c[2*i]*rho[des[2*i-1]]*rho[des[2*i]+1]*s[2*i-1]*s[2*i]+pow(c[2*i],2))/(pow(s[2*i-1],2)*(1-pow(rho[des[2*i-1]],2)))
prob.pub[2*i-1]<-phi(u[2*i-1])
pub.stud[2*i-1]<-1/prob.pub[2*i-1]
prob.pub[2*i]<-0
pub.stud[2*i]<-0
}
for(i in 1:12)  {
w[i]<-1/vy[i]
mu[i]~dnorm(mean[i],prec)
# consistency equation on the adjusted mean values
mean[i]<-d[t[i]]-d[b[i]]
}
# the following four lines are needed if we place a restriction on the correlation coefficients. All three standard errors are needed from #each multi-arm study. The third standard error s_BC can be computed from s_AB, s_AC and c=cov(y_AB,y_AC) or can be put as data #s(38:43)
for (i in 1:6) {
rhos[i]<-(s[2*i]*rhot[i,des[2*i]+1]-s[2*i-1]*rhot[i,des[2*i]])/s[N+i]
thres[i]<-rho[des[2*i]]*c[2*i]/(s[2*i]*s[2*i-1])
rhot[i,des[2*i]]~dnorm(rho[des[2*i]],rho_tau)  %_% T(-1,thres[i])
low[i]<-max(-1,(-s[N+i]+rhot[i,des[2*i]]*s[2*i-1])/s[2*i])
high[i]<-min(1,(s[N+i]+rhot[i,des[2*i]]*s[2*i-1])/s[2*i])
rhot[i,des[2*i]+1]~dnorm(rho[des[2*i]+1],rho_tau) %_% T(low[i],high[i])
}
rhof<-mean(rhos[1:6])
rho_tau~dnorm(0,0.1)%_% T(0,)
for(i in 13:N)  {
u[i]<-alpha[des[i]]+beta[des[i]]/s[i]
z[i]~dnorm(u[i],1)%_% T(0,)
y[i]~dnorm(my[i],w[i])
R[i]<-rho[des[i]+1]*s[i]*(z[i]-u[i])
my[i]<-mu[i]+R[i]
vy[i]<-pow(s[i],2)*(1-pow(rho[des[i]+1],2))
w[i]<-1/vy[i]
mu[i]~dnorm(mean[i],prec)
mean[i]<-d[t[i]]-d[b[i]]
# probability of publication for a study
prob.pub[i]<-phi(u[i])
# total number of studies similar to study i (including study (i))
pub.stud[i]<-1/prob.pub[i]
}
df[4]<-d[3]-d[2]
#More than two treatments
#------------------------------------------------------------
###3. Useful parametrisation of the means
#---------------------------------------------------------------
# total number of studies, both published and unpublished for each design
tot.pub[1]<-sum(pub.stud[1:12])
tot.pub[2]<-sum(pub.stud[13:16])
tot.pub[3]<-sum(pub.stud[17:30])
tot.pub[4]<-sum(pub.stud[31:37])
d[1]<-0
for (k in 2:NT)  {d[k] ~ dnorm(0,.0001) }
###### PRIORS##################################
prec<-1/pow(tau,2)
tau~dnorm(0,0.01)%_% T(0,)
for (j in 1:D+1) {
rho1[j]~dunif(0,2)
rho[j]<-rho1[j]-1
}
for(i in 1:12)  {DD[i]<-w[i]*(y[i]-my[i])*(y[i]-my[i])}
#More than two treatments
for(i in 13:N){
DD[i]<-(y[i]-my[i])*(y[i]-my[i])*w[i]}
D.bar<-sum(DD[])
for(k in 1:NT){order[k]<-NT+1-rank(d[],k)
most.effective[k]<-equals(order[k],1)
for(j in 1:NT){
effectiveness[k,j]<-equals(order[k],j)
}}
for(k in 1:NT){
for(j in 1:NT){
cumeffectiveness[k,j]<-sum(effectiveness[k,1:j])
}
}
for(k in 1:NT){
SUCRA[k]<-sum(cumeffectiveness[k,1:(NT-1)])/(NT-1)
}
}
CopasJAGS<- jags(data=mydata, inits = NULL,
parameters.to.save = c("mean","rho","tau"), n.chains = 1, n.iter = 10000,
n.burnin = 1000,DIC=F,
model.file = Copas.fullmodel)
rm(list=ls())
library(devtools)
library(nmadb)
library(readxl)
install_github("esm-ispm-unibe-ch/rankingagreement")
library(rankingagreement)
install_github("esm-ispm-unibe-ch/NMAJags")
library(NMAJags)
library(R2jags)
library(netmeta)
library(ircor)
install.packages("xlsx")
library(xlsx)
loadOrRun = function (filename, runfunction){
if(file.exists(filename)){
out = readRDS(filename)
}else{
out = runfunction()
}
return(out)
}
# access database or locally saved file
nmadb=loadOrRun("nmadb.RData",
function () {
ndb = getNMADB()
saveRDS(file = "./nmadb.RData", object = ndb)
return(ndb)}
)
#nmadb = getNMADB()
# nmadb_used = nmadb[nmadb$Verified=="True" & nmadb$Format!="iv" & (nmadb$Type.of.Outcome.=="Binary" | nmadb$Type.of.Outcome.=="Continuous"),]
# get IDs of networks separately for binary and continuous outcome; those with inverse-variance excluded
binaryIDs = nmadb[nmadb$Verified=="True" & nmadb$Type.of.Outcome.=="Binary" & nmadb$Format!="iv",]$Record.ID
continuousIDs = nmadb[nmadb$Verified=="True" & nmadb$Type.of.Outcome.=="Continuous" & nmadb$Format!="iv",]$Record.ID
# the following functions get the netmetas and the datas for all the networks with continuous outcomes
getContinuousNMAs = function() {
out = lapply(continuousIDs,
function(rid)
return(list(rid=rid,netobj=runnetmeta(rid)))
)
return(out)
}
continuousNetObjects = loadOrRun("continuousNetObjects.RData",
function () {
nmas = getContinuousNMAs()
saveRDS(file = "./continuousNetObjects.RData", object = nmas)
return(nmas)}
)
getContinuousDatasets = function() {
out = lapply(continuousIDs,
function(rid)
return(readByID(rid))
)
return(out)
}
continuousDatasets = loadOrRun("continuousDatasets.RData",
function () {
datas = getContinuousDatasets()
saveRDS(file = "./continuousDatasets.RData", object = datas)
return(datas)}
)
# calculate ranking metrics for continuous outcome networks
getContinuous = function () {
out = lapply( 1:length(continuousNetObjects),
function(i) {
tryCatch({
nma = continuousNetObjects[[i]]$netobj
rid = continuousNetObjects[[i]]$rid
netd = continuousDatasets[[i]]
if (nmadb[nmadb$Record.ID==rid,]$Harmful.Beneficial.Outcome=="Beneficial"){
nmaranks = netmetaranks_B(nma,1000)
altnma = alternativenma(nma, small.values = "bad")
jagsranks = nmajagsranks_con_B(netd$data)
}
else {
nmaranks = netmetaranks_H(nma,1000)
altnma = alternativenma(nma)
jagsranks = nmajagsranks_con(netd$data)
}
return(list("no. treatments"=nma$n, "no. studies"=nma$k,"sample size"=sum(netd$data$n),
"ranking metrics"=cbind(nmaranks[order(as.numeric(rownames(nmaranks))),],
jagsranks, "Avg TE"=altnma$averages[order(as.numeric(rownames(altnma$averages))),]$TE,
"Avg TE ranks"=altnma$averages[order(as.numeric(rownames(altnma$averages))),]$TE_ranks,
"Avg Pscore"=altnma$averages[order(as.numeric(rownames(altnma$averages))),]$Pscoreaverage),
"Avg TE prec range"=(max(altnma$averages$seTE^2)-min(altnma$averages$seTE^2))/max(altnma$averages$seTE^2),
"Avg TE prec avg"=mean(altnma$averages$seTE^2)))
},  error=function(cond){
message(cond)
return(list(recid=rid,error=cond))
}
)
}
)
return(out)
}
pdf("traceplots_cont.pdf")
continuous_rm = loadOrRun("continuousRM.RData",
function () {
conts = getContinuous()
saveRDS(file = "./continuousRM.RData", object = conts)
return(conts)}
)
# continuous_rm =  getContinuous()
dev.off()
names(continuous_rm) <- as.character(continuousIDs)
head(continuous_rm)
# the following functions get the netmetas and the datas for all the networks with continuous outcomes
getBinaryNMAs = function() {
out = lapply(binaryIDs,
function(rid)
return(list(rid=rid,netobj=runnetmeta(rid)))
)
return(out)
}
binaryNetObjects = loadOrRun("binaryNetObjects.RData",
function () {
nmas = getBinaryNMAs()
saveRDS(file = "./binaryNetObjects.RData", object = nmas)
return(nmas)}
)
getBinaryDatasets = function() {
out = lapply(binaryIDs,
function(rid)
return(readByID(rid))
)
return(out)
}
binaryDatasets = loadOrRun("binaryDatasets.RData",
function () {
datas = getBinaryDatasets()
saveRDS(file = "./binaryDatasets.RData", object = datas)
return(datas)}
)
# calculate ranking metrics for binary outcome networks
getBinary = function () {
out  = lapply( 1:length(binaryNetObjects),
function(i) {
tryCatch({
nma = binaryNetObjects[[i]]$netobj
rid = binaryNetObjects[[i]]$rid
netd = binaryDatasets[[i]]
if (nmadb[nmadb$Record.ID==rid,]$Harmful.Beneficial.Outcome=="Beneficial"){
nmaranks = netmetaranks_B(nma,1000)
altnma = alternativenma(nma, small.values = "bad")
jagsranks = nmajagsranks_bin_B(netd$data)
}
else {
nmaranks = netmetaranks_H(nma,1000)
altnma = alternativenma(nma)
jagsranks = nmajagsranks_bin(netd$data)
}
return(list("no. treatments"=nma$n, "no. studies"=nma$k,"sample size"=sum(netd$data$n),
"ranking metrics"=cbind(nmaranks[order(as.numeric(rownames(nmaranks))),],
jagsranks, "Avg TE"=altnma$averages[order(as.numeric(rownames(altnma$averages))),]$TE,
"Avg TE ranks"=altnma$averages[order(as.numeric(rownames(altnma$averages))),]$TE_ranks,
"Avg Pscore"=altnma$averages[order(as.numeric(rownames(altnma$averages))),]$Pscoreaverage),
"Avg TE prec range"=(max(altnma$averages$seTE^2)-min(altnma$averages$seTE^2))/max(altnma$averages$seTE^2),
"Avg TE prec avg"=mean(altnma$averages$seTE^2)))                     },   error=function(cond){
message(cond)
return(list(recid=rid,error=cond))
}
)
}
)
}
pdf("traceplots_bin.pdf")
binary_rm = loadOrRun("binaryRM.RData",
function () {
bin = getBinary()
saveRDS(file = "./binaryRM.RData", object = bin)
return(bin)}
)
# binary_rm =  getBinary()
dev.off()
names(binary_rm) <- as.character(binaryIDs)
head(binary_rm)
con_ranks <- lapply(1:length(continuous_rm), function(i) continuous_rm[[i]][["ranking metrics"]][,grepl("rank",colnames(continuous_rm[[i]][["ranking metrics"]]))])
names(con_ranks) <- as.character(continuousIDs)
head(con_ranks)
bin_ranks <- lapply(1:length(binary_rm), function(i) binary_rm[[i]][["ranking metrics"]][,grepl("rank",colnames(binary_rm[[i]][["ranking metrics"]]))])
names(bin_ranks) <- as.character(binaryIDs)
head(bin_ranks)
# create lists with only ranking metrics values for spearman correlation
# con_values <- lapply(1:length(continuous_rm), function(i) continuous_rm[[i]][["ranking metrics"]][,c(1,3,5,7,8,9,11,13)])
# bin_values <- lapply(1:length(binary_rm), function(i) binary_rm[[i]][["ranking metrics"]][,c(1,3,5,7,8,9,11,13)])
# calculate kendall correlation
kendall_con <- lapply(con_ranks, cor, method="kendall")
names(kendall_con) <- as.character(continuousIDs)
head(kendall_con)
kendall_bin <- lapply(bin_ranks, cor, method="kendall")
names(kendall_bin) <- as.character(binaryIDs)
head(kendall_bin)
# calculate spearman correlation
spearman_con <- lapply(con_ranks, cor, method="spearman")
names(spearman_con) <- as.character(continuousIDs)
head(spearman_con)
spearman_bin <- lapply(bin_ranks, cor, method="spearman")
names(spearman_bin) <- as.character(binaryIDs)
head(spearman_bin)
# checks for P-score and SUCRA ranks
pSCOREvsSUCRA_s <- c(sapply(1:length(con_ranks), function(i) spearman_con[[i]]["Pscore_ranks","SUCRA_ranks"]),
sapply(1:length(bin_ranks), function(i) spearman_bin[[i]]["Pscore_ranks","SUCRA_ranks"]))
names(pSCOREvsSUCRA_s) <- as.character(c(continuousIDs,binaryIDs))
res_pSCOREvsSUCRA_s <- paste0(summary(pSCOREvsSUCRA_s, digits = 3)["Median"], " (", summary(pSCOREvsSUCRA_s, digits = 3)["1st Qu."], ", ", summary(pSCOREvsSUCRA_s, digits = 3)["3rd Qu."], ")")
sum(pSCOREvsSUCRA_s>0.99)/length(pSCOREvsSUCRA_s) # % of networks with spearman correlation >0.99
print(pSCOREvsSUCRA_s[pSCOREvsSUCRA_s<0.99999])
# prepare matrix to store results
results <- matrix(nrow = 4, ncol = 4,
dimnames = list(c("Spearman rho", "Kendall tau", "Yilmaz tauAP", "Average Overlap"),
c("pBV vs SUCRA", "SUCRA vs ATE", "pBV vs ATE", "SUCRA vs SUCRAjags")))
# save all pBV vs SUCRA in a vector separately for kendall, spearman and AP then store median and interquartile range
pBVvsSUCRA_s <- c(sapply(1:length(con_ranks), function(i) spearman_con[[i]]["pBV ranks","SUCRA_ranks"]),
sapply(1:length(bin_ranks), function(i) spearman_bin[[i]]["pBV ranks","SUCRA_ranks"]))
names(pBVvsSUCRA_s) <- as.character(c(continuousIDs,binaryIDs))
pBVvsSUCRA_k <- c(sapply(1:length(con_ranks), function(i) kendall_con[[i]]["pBV ranks","SUCRA_ranks"]),
sapply(1:length(bin_ranks), function(i) kendall_bin[[i]]["pBV ranks","SUCRA_ranks"]))
names(pBVvsSUCRA_k) <- as.character(c(continuousIDs,binaryIDs))
pBVvsSUCRA_AP <- c(sapply(1:length(con_ranks), function(i) tauAP_b(con_ranks[[i]][,"pBV ranks"], con_ranks[[i]][,"SUCRA_ranks"], decreasing=F)),
sapply(1:length(bin_ranks), function(i) tauAP_b(bin_ranks[[i]][,"pBV ranks"], bin_ranks[[i]][,"SUCRA_ranks"], decreasing=F)))
names(pBVvsSUCRA_AP) <- as.character(c(continuousIDs,binaryIDs))
pBVvsSUCRA_AO <- c(sapply(1:length(con_ranks), function(i) if(as.numeric(continuous_rm[[i]]["no. treatments"])>5)
{averageoverlap(order(con_ranks[[i]][,"pBV ranks"]),order(con_ranks[[i]][,"SUCRA_ranks"]),floor(as.numeric(continuous_rm[[i]]["no. treatments"])/2))}
else {NA}),
sapply(1:length(bin_ranks), function(i) if(as.numeric(binary_rm[[i]]["no. treatments"])>5)
{averageoverlap(order(bin_ranks[[i]][,"pBV ranks"]),order(bin_ranks[[i]][,"SUCRA_ranks"]),floor(as.numeric(binary_rm[[i]]["no. treatments"])/2))}
else {NA}))
names(pBVvsSUCRA_AO) <- as.character(c(continuousIDs,binaryIDs))
pBVvsSUCRA_AO <- Filter(Negate(anyNA), pBVvsSUCRA_AO)   ## exclude any NAs
head(pBVvsSUCRA_s)
head(pBVvsSUCRA_k)
head(pBVvsSUCRA_AP)
head(pBVvsSUCRA_AO)
results["Spearman rho","pBV vs SUCRA"] <- paste0(summary(pBVvsSUCRA_s, digits = 2)["Median"], " (", summary(pBVvsSUCRA_s, digits = 2)["1st Qu."], ", ", summary(pBVvsSUCRA_s, digits = 2)["3rd Qu."], ")")
results["Kendall tau","pBV vs SUCRA"] <-paste0(summary(pBVvsSUCRA_k, digits = 2)["Median"], " (", summary(pBVvsSUCRA_k, digits = 2)["1st Qu."], ", ", summary(pBVvsSUCRA_k, digits = 2)["3rd Qu."], ")")
results["Yilmaz tauAP","pBV vs SUCRA"] <-paste0(summary(pBVvsSUCRA_AP, digits = 2)["Median"], " (", summary(pBVvsSUCRA_AP, digits = 2)["1st Qu."], ", ", summary(pBVvsSUCRA_AP, digits = 2)["3rd Qu."], ")")
results["Average Overlap","pBV vs SUCRA"] <-paste0(summary(pBVvsSUCRA_AO, digits = 2)["Median"], " (", summary(pBVvsSUCRA_AO, digits = 2)["1st Qu."], ", ", summary(pBVvsSUCRA_AO, digits = 2)["3rd Qu."], ")")
# save all SUCRA vs Avg TE in a vector separately for kendall, spearman and AP, then store median and interquartile range
SUCRAvsAvgTE_s <- c(sapply(1:length(con_ranks), function(i) spearman_con[[i]]["SUCRA_ranks","Avg TE ranks"]),
sapply(1:length(bin_ranks), function(i) spearman_bin[[i]]["SUCRA_ranks","Avg TE ranks"]))
names(SUCRAvsAvgTE_s) <- as.character(c(continuousIDs,binaryIDs))
SUCRAvsAvgTE_k <- c(sapply(1:length(con_ranks), function(i) kendall_con[[i]]["SUCRA_ranks","Avg TE ranks"]),
sapply(1:length(bin_ranks), function(i) kendall_bin[[i]]["SUCRA_ranks","Avg TE ranks"]))
names(SUCRAvsAvgTE_k) <- as.character(c(continuousIDs,binaryIDs))
SUCRAvsAvgTE_AP <- c(sapply(1:length(con_ranks), function(i) tauAP_b(con_ranks[[i]][,"SUCRA_ranks"], con_ranks[[i]][,"Avg TE ranks"], decreasing=F)),
sapply(1:length(bin_ranks), function(i) tauAP_b(bin_ranks[[i]][,"SUCRA_ranks"], bin_ranks[[i]][,"Avg TE ranks"], decreasing=F)))
names(SUCRAvsAvgTE_AP) <- as.character(c(continuousIDs,binaryIDs))
SUCRAvsAvgTE_AO <- c(sapply(1:length(con_ranks), function(i) if(as.numeric(continuous_rm[[i]]["no. treatments"])>5)
{averageoverlap(order(con_ranks[[i]][,"SUCRA_ranks"]),order(con_ranks[[i]][,"Avg TE ranks"]),floor(as.numeric(continuous_rm[[i]]["no. treatments"])/2))}
else {NA}),
sapply(1:length(bin_ranks), function(i) if(as.numeric(binary_rm[[i]]["no. treatments"])>5)
{averageoverlap(order(bin_ranks[[i]][,"SUCRA_ranks"]),order(bin_ranks[[i]][,"Avg TE ranks"]),floor(as.numeric(binary_rm[[i]]["no. treatments"])/2))}
else {NA}))
names(SUCRAvsAvgTE_AO) <- as.character(c(continuousIDs,binaryIDs))
SUCRAvsAvgTE_AO <- Filter(Negate(anyNA), SUCRAvsAvgTE_AO)   ## exclude any NAs
head(SUCRAvsAvgTE_s)
head(SUCRAvsAvgTE_k)
head(SUCRAvsAvgTE_AP)
head(SUCRAvsAvgTE_AO)
results["Spearman rho","SUCRA vs ATE"] <- paste0(summary(SUCRAvsAvgTE_s, digits = 2)["Median"], " (", summary(SUCRAvsAvgTE_s, digits = 2)["1st Qu."], ", ", summary(SUCRAvsAvgTE_s, digits = 2)["3rd Qu."], ")")
results["Kendall tau","SUCRA vs ATE"]  <- paste0(summary(SUCRAvsAvgTE_k, digits = 2)["Median"], " (", summary(SUCRAvsAvgTE_k, digits = 2)["1st Qu."], ", ", summary(SUCRAvsAvgTE_k, digits = 2)["3rd Qu."], ")")
results["Yilmaz tauAP","SUCRA vs ATE"] <- paste0(summary(SUCRAvsAvgTE_AP, digits = 2)["Median"], " (", summary(SUCRAvsAvgTE_AP, digits = 2)["1st Qu."], ", ", summary(SUCRAvsAvgTE_AP, digits = 2)["3rd Qu."], ")")
results["Average Overlap","SUCRA vs ATE"] <-paste0(summary(SUCRAvsAvgTE_AO, digits = 2)["Median"], " (", summary(SUCRAvsAvgTE_AO, digits = 2)["1st Qu."], ", ", summary(SUCRAvsAvgTE_AO, digits = 2)["3rd Qu."], ")")
# save all pBV vs Avg TE in a vector separately for kendall, spearman and AP then store median and interquartile range
pBVvsAvgTE_s <- c(sapply(1:length(con_ranks), function(i) spearman_con[[i]]["pBV ranks","Avg TE ranks"]),
sapply(1:length(bin_ranks), function(i) spearman_bin[[i]]["pBV ranks","Avg TE ranks"]))
names(pBVvsAvgTE_s) <- as.character(c(continuousIDs,binaryIDs))
pBVvsAvgTE_k <- c(sapply(1:length(con_ranks), function(i) kendall_con[[i]]["pBV ranks","Avg TE ranks"]),
sapply(1:length(bin_ranks), function(i) kendall_bin[[i]]["pBV ranks","Avg TE ranks"]))
names(pBVvsAvgTE_k) <- as.character(c(continuousIDs,binaryIDs))
pBVvsAvgTE_AP <- c(sapply(1:length(con_ranks), function(i) tauAP_b(con_ranks[[i]][,"pBV ranks"], con_ranks[[i]][,"Avg TE ranks"], decreasing=F)),
sapply(1:length(bin_ranks), function(i) tauAP_b(bin_ranks[[i]][,"pBV ranks"], bin_ranks[[i]][,"Avg TE ranks"], decreasing=F)))
names(pBVvsAvgTE_AP) <- as.character(c(continuousIDs,binaryIDs))
pBVvsAvgTE_AO <- c(sapply(1:length(con_ranks), function(i) if(as.numeric(continuous_rm[[i]]["no. treatments"])>5)
{averageoverlap(order(con_ranks[[i]][,"pBV ranks"]),order(con_ranks[[i]][,"Avg TE ranks"]),floor(as.numeric(continuous_rm[[i]]["no. treatments"])/2))}
else {NA}),
sapply(1:length(bin_ranks), function(i) if(as.numeric(binary_rm[[i]]["no. treatments"])>5)
{averageoverlap(order(bin_ranks[[i]][,"pBV ranks"]),order(bin_ranks[[i]][,"Avg TE ranks"]),floor(as.numeric(binary_rm[[i]]["no. treatments"])/2))}
else {NA}))
names(pBVvsAvgTE_AO) <- as.character(c(continuousIDs,binaryIDs))
pBVvsAvgTE_AO <- Filter(Negate(anyNA), pBVvsAvgTE_AO)   ## exclude any NAs
head(pBVvsAvgTE_s)
head(pBVvsAvgTE_k)
head(pBVvsAvgTE_AP)
head(pBVvsAvgTE_AO)
results["Spearman rho","pBV vs ATE"] <- paste0(summary(pBVvsAvgTE_s, digits = 2)["Median"], " (", summary(pBVvsAvgTE_s, digits = 2)["1st Qu."], ", ", summary(pBVvsAvgTE_s, digits = 2)["3rd Qu."], ")")
results["Kendall tau","pBV vs ATE"]  <-paste0(summary(pBVvsAvgTE_k, digits = 2)["Median"], " (", summary(pBVvsAvgTE_k, digits = 2)["1st Qu."], ", ", summary(pBVvsAvgTE_k, digits = 2)["3rd Qu."], ")")
results["Yilmaz tauAP","pBV vs ATE"]  <-paste0(summary(pBVvsAvgTE_AP, digits = 2)["Median"], " (", summary(pBVvsAvgTE_AP, digits = 2)["1st Qu."], ", ", summary(pBVvsAvgTE_AP, digits = 2)["3rd Qu."], ")")
results["Average Overlap","pBV vs ATE"] <-paste0(summary(pBVvsAvgTE_AO, digits = 2)["Median"], " (", summary(pBVvsAvgTE_AO, digits = 2)["1st Qu."], ", ", summary(pBVvsAvgTE_AO, digits = 2)["3rd Qu."], ")")
# save all SUCRA vs SUCRA jags in a vector separately for kendall and spearman, then store proportion of network with values >0.9
SUCRAvsSUCRAjags_s <- c(sapply(1:length(con_ranks), function(i) spearman_con[[i]]["SUCRA_ranks","SUCRAjags ranks"]),
sapply(1:length(bin_ranks), function(i) spearman_bin[[i]]["SUCRA_ranks","SUCRAjags ranks"]))
names(SUCRAvsSUCRAjags_s) <- as.character(c(continuousIDs,binaryIDs))
SUCRAvsSUCRAjags_k <- c(sapply(1:length(con_ranks), function(i) kendall_con[[i]]["SUCRA_ranks","SUCRAjags ranks"]),
sapply(1:length(bin_ranks), function(i) kendall_bin[[i]]["SUCRA_ranks","SUCRAjags ranks"]))
names(SUCRAvsSUCRAjags_k) <- as.character(c(continuousIDs,binaryIDs))
SUCRAvsSUCRAjags_AP <- c(sapply(1:length(con_ranks), function(i) tauAP_b(con_ranks[[i]][,"SUCRA_ranks"], con_ranks[[i]][,"SUCRAjags ranks"], decreasing=F)),
sapply(1:length(bin_ranks), function(i) tauAP_b(bin_ranks[[i]][,"SUCRA_ranks"], bin_ranks[[i]][,"SUCRAjags ranks"], decreasing=F)))
names(SUCRAvsSUCRAjags_AP) <- as.character(c(continuousIDs,binaryIDs))
SUCRAvsSUCRAjags_AO <- c(sapply(1:length(con_ranks), function(i) if(as.numeric(continuous_rm[[i]]["no. treatments"])>5)
{averageoverlap(order(con_ranks[[i]][,"SUCRA_ranks"]),order(con_ranks[[i]][,"SUCRAjags ranks"]),floor(as.numeric(continuous_rm[[i]]["no. treatments"])/2))}
else {NA}),
sapply(1:length(bin_ranks), function(i) if(as.numeric(binary_rm[[i]]["no. treatments"])>5)
{averageoverlap(order(bin_ranks[[i]][,"SUCRA_ranks"]),order(bin_ranks[[i]][,"SUCRAjags ranks"]),floor(as.numeric(binary_rm[[i]]["no. treatments"])/2))}
else {NA}))
names(SUCRAvsSUCRAjags_AO) <- as.character(c(continuousIDs,binaryIDs))
SUCRAvsSUCRAjags_AO <- Filter(Negate(anyNA), SUCRAvsSUCRAjags_AO)   ## exclude any NAs
head(SUCRAvsSUCRAjags_s)
head(SUCRAvsSUCRAjags_k)
head(SUCRAvsSUCRAjags_AP)
head(SUCRAvsSUCRAjags_AO)
results["Spearman rho","SUCRA vs SUCRAjags"] <- paste0(summary(SUCRAvsSUCRAjags_s, digits = 2)["Median"], " (", summary(SUCRAvsSUCRAjags_s, digits = 2)["1st Qu."], ", ", summary(SUCRAvsSUCRAjags_s, digits = 2)["3rd Qu."], ")")
results["Kendall tau","SUCRA vs SUCRAjags"]  <- paste0(summary(SUCRAvsSUCRAjags_k, digits = 2)["Median"], " (", summary(SUCRAvsSUCRAjags_k, digits = 2)["1st Qu."], ", ", summary(SUCRAvsSUCRAjags_k, digits = 2)["3rd Qu."], ")")
results["Yilmaz tauAP","SUCRA vs SUCRAjags"] <- paste0(summary(SUCRAvsSUCRAjags_AP, digits = 2)["Median"], " (", summary(SUCRAvsSUCRAjags_AP, digits = 2)["1st Qu."], ", ", summary(SUCRAvsSUCRAjags_AP, digits = 2)["3rd Qu."], ")")
results["Average Overlap","SUCRA vs SUCRAjags"] <-paste0(summary(SUCRAvsSUCRAjags_AO, digits = 2)["Median"], " (", summary(SUCRAvsSUCRAjags_AO, digits = 2)["1st Qu."], ", ", summary(SUCRAvsSUCRAjags_AO, digits = 2)["3rd Qu."], ")")
SUCRAs_90 <- sum(SUCRAvsSUCRAjags_s>0.9)/length(SUCRAvsSUCRAjags_s) # % of networks with spearman correlation >0.9
SUCRAk_90 <- sum(SUCRAvsSUCRAjags_k>0.9)/length(SUCRAvsSUCRAjags_k) # % of networks with kendall correlation >0.9
SUCRAap_90 <-  sum(SUCRAvsSUCRAjags_AP>0.9)/length(SUCRAvsSUCRAjags_AP) # % of networks with Yilmaz AP correlation >0.9
SUCRAao_90 <- sum(SUCRAvsSUCRAjags_AO>0.9)/length(SUCRAvsSUCRAjags_AO)# % of networks with AO >0.9
# export matrix results in table
write.xlsx(results, "agreement results.xlsx")
View(results)
SUCRAvsAvgTE_s[SUCRAvsAvgTE_s<0.9]
View(nmadb)
binary_rm["501407"]
binary_rm["501263"]
